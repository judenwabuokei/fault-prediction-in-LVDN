{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP6JLo1tGNBg"
   },
   "source": [
    "# Faults Location Prediction Using Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWZyYmS_UE_L"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxkJoQBkUIHC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKWAkFVGUU0Z"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXUkhkMfU4wq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fault_location</th>\n",
       "      <th>Fault_section</th>\n",
       "      <th>Fault_type</th>\n",
       "      <th>632_Active_PhaseA</th>\n",
       "      <th>632_Active_PhaseB</th>\n",
       "      <th>632_Active_PhaseC</th>\n",
       "      <th>633_Active_PhaseA</th>\n",
       "      <th>633_Active_PhaseB</th>\n",
       "      <th>633_Active_PhaseC</th>\n",
       "      <th>692_Active_PhaseA</th>\n",
       "      <th>...</th>\n",
       "      <th>692_Active_PhaseC</th>\n",
       "      <th>671_Active_PhaseA</th>\n",
       "      <th>671_Active_PhaseB</th>\n",
       "      <th>671_Active_PhaseC</th>\n",
       "      <th>645_Active_PhaseA</th>\n",
       "      <th>645_Active_PhaseB</th>\n",
       "      <th>645_Active_PhaseC</th>\n",
       "      <th>684_Active_PhaseA</th>\n",
       "      <th>684_Active_PhaseB</th>\n",
       "      <th>684_Active_PhaseC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.130</td>\n",
       "      <td>0.9087</td>\n",
       "      <td>1.189</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2534</td>\n",
       "      <td>-0.9627</td>\n",
       "      <td>-0.4158</td>\n",
       "      <td>-0.8718</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.331700</td>\n",
       "      <td>-0.79430</td>\n",
       "      <td>-0.1243</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.108</td>\n",
       "      <td>0.8908</td>\n",
       "      <td>1.166</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.4522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2484</td>\n",
       "      <td>-0.9437</td>\n",
       "      <td>-0.4076</td>\n",
       "      <td>-0.8545</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.325300</td>\n",
       "      <td>-0.07786</td>\n",
       "      <td>-0.1219</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>134.500</td>\n",
       "      <td>116.1000</td>\n",
       "      <td>127.500</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>-0.9622</td>\n",
       "      <td>-0.4157</td>\n",
       "      <td>-0.8714</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.331600</td>\n",
       "      <td>-0.07940</td>\n",
       "      <td>-0.1243</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>89.550</td>\n",
       "      <td>77.3400</td>\n",
       "      <td>85.400</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.4611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>-0.9624</td>\n",
       "      <td>-0.4157</td>\n",
       "      <td>-0.8716</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.331700</td>\n",
       "      <td>-0.07910</td>\n",
       "      <td>-0.1243</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>67.220</td>\n",
       "      <td>58.0600</td>\n",
       "      <td>64.360</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.4612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>-0.9624</td>\n",
       "      <td>-0.4157</td>\n",
       "      <td>-0.8716</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.331700</td>\n",
       "      <td>-0.07942</td>\n",
       "      <td>-0.1243</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>11.9</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1.130</td>\n",
       "      <td>25.0900</td>\n",
       "      <td>1.194</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2534</td>\n",
       "      <td>-0.9627</td>\n",
       "      <td>-0.4158</td>\n",
       "      <td>-0.8718</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.003662</td>\n",
       "      <td>-0.11320</td>\n",
       "      <td>-0.1243</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>12.3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1.130</td>\n",
       "      <td>21.0300</td>\n",
       "      <td>1.195</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2534</td>\n",
       "      <td>-0.9627</td>\n",
       "      <td>-0.4158</td>\n",
       "      <td>-0.8718</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.557000</td>\n",
       "      <td>-0.10910</td>\n",
       "      <td>-0.1243</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>12.5</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1.130</td>\n",
       "      <td>19.4700</td>\n",
       "      <td>1.195</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2534</td>\n",
       "      <td>-0.9627</td>\n",
       "      <td>-0.4158</td>\n",
       "      <td>-0.8718</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.264000</td>\n",
       "      <td>-0.10760</td>\n",
       "      <td>-0.1243</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>12.7</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1.130</td>\n",
       "      <td>18.1300</td>\n",
       "      <td>1.195</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2534</td>\n",
       "      <td>-0.9627</td>\n",
       "      <td>-0.4158</td>\n",
       "      <td>-0.8718</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.739000</td>\n",
       "      <td>-0.10620</td>\n",
       "      <td>-0.1243</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>12.9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1.130</td>\n",
       "      <td>15.9600</td>\n",
       "      <td>1.196</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2534</td>\n",
       "      <td>-0.9627</td>\n",
       "      <td>-0.4158</td>\n",
       "      <td>-0.8718</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.250000</td>\n",
       "      <td>-0.10400</td>\n",
       "      <td>-0.1243</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fault_location  Fault_section  Fault_type  632_Active_PhaseA  \\\n",
       "0               0.0              0           0              1.130   \n",
       "1               1.0              1           1              1.108   \n",
       "2               2.3              2           1            134.500   \n",
       "3               2.5              2           1             89.550   \n",
       "4               2.7              2           1             67.220   \n",
       "..              ...            ...         ...                ...   \n",
       "152            11.9             11           4              1.130   \n",
       "153            12.3             12           4              1.130   \n",
       "154            12.5             12           4              1.130   \n",
       "155            12.7             12           4              1.130   \n",
       "156            12.9             12           4              1.130   \n",
       "\n",
       "     632_Active_PhaseB  632_Active_PhaseC  633_Active_PhaseA  \\\n",
       "0               0.9087              1.189           0.142200   \n",
       "1               0.8908              1.166           0.139400   \n",
       "2             116.1000            127.500           0.000201   \n",
       "3              77.3400             85.400           0.000087   \n",
       "4              58.0600             64.360           0.000048   \n",
       "..                 ...                ...                ...   \n",
       "152            25.0900              1.194           0.142200   \n",
       "153            21.0300              1.195           0.142200   \n",
       "154            19.4700              1.195           0.142200   \n",
       "155            18.1300              1.195           0.142200   \n",
       "156            15.9600              1.196           0.142200   \n",
       "\n",
       "     633_Active_PhaseB  633_Active_PhaseC  692_Active_PhaseA  ...  \\\n",
       "0             0.104900           0.104900             0.4613  ...   \n",
       "1             0.102800           0.102900             0.4522  ...   \n",
       "2             0.000184           0.000046             0.4610  ...   \n",
       "3             0.000088           0.000021             0.4611  ...   \n",
       "4             0.000052           0.000013             0.4612  ...   \n",
       "..                 ...                ...                ...  ...   \n",
       "152           0.104900           0.104900             0.4613  ...   \n",
       "153           0.104900           0.104900             0.4613  ...   \n",
       "154           0.104900           0.104900             0.4613  ...   \n",
       "155           0.104900           0.104900             0.4613  ...   \n",
       "156           0.104900           0.104900             0.4613  ...   \n",
       "\n",
       "     692_Active_PhaseC  671_Active_PhaseA  671_Active_PhaseB  \\\n",
       "0               0.2534            -0.9627            -0.4158   \n",
       "1               0.2484            -0.9437            -0.4076   \n",
       "2               0.2533            -0.9622            -0.4157   \n",
       "3               0.2533            -0.9624            -0.4157   \n",
       "4               0.2533            -0.9624            -0.4157   \n",
       "..                 ...                ...                ...   \n",
       "152             0.2534            -0.9627            -0.4158   \n",
       "153             0.2534            -0.9627            -0.4158   \n",
       "154             0.2534            -0.9627            -0.4158   \n",
       "155             0.2534            -0.9627            -0.4158   \n",
       "156             0.2534            -0.9627            -0.4158   \n",
       "\n",
       "     671_Active_PhaseC  645_Active_PhaseA  645_Active_PhaseB  \\\n",
       "0              -0.8718                  0          -0.331700   \n",
       "1              -0.8545                  0          -0.325300   \n",
       "2              -0.8714                  0          -0.331600   \n",
       "3              -0.8716                  0          -0.331700   \n",
       "4              -0.8716                  0          -0.331700   \n",
       "..                 ...                ...                ...   \n",
       "152            -0.8718                  0          -0.003662   \n",
       "153            -0.8718                  0          -4.557000   \n",
       "154            -0.8718                  0          -5.264000   \n",
       "155            -0.8718                  0          -5.739000   \n",
       "156            -0.8718                  0          -6.250000   \n",
       "\n",
       "     645_Active_PhaseC  684_Active_PhaseA  684_Active_PhaseB  \\\n",
       "0             -0.79430            -0.1243                  0   \n",
       "1             -0.07786            -0.1219                  0   \n",
       "2             -0.07940            -0.1243                  0   \n",
       "3             -0.07910            -0.1243                  0   \n",
       "4             -0.07942            -0.1243                  0   \n",
       "..                 ...                ...                ...   \n",
       "152           -0.11320            -0.1243                  0   \n",
       "153           -0.10910            -0.1243                  0   \n",
       "154           -0.10760            -0.1243                  0   \n",
       "155           -0.10620            -0.1243                  0   \n",
       "156           -0.10400            -0.1243                  0   \n",
       "\n",
       "     684_Active_PhaseC  \n",
       "0              -0.1667  \n",
       "1              -0.1634  \n",
       "2              -0.1666  \n",
       "3              -0.1666  \n",
       "4              -0.1667  \n",
       "..                 ...  \n",
       "152            -0.1667  \n",
       "153            -0.1667  \n",
       "154            -0.1667  \n",
       "155            -0.1667  \n",
       "156            -0.1667  \n",
       "\n",
       "[157 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faults = pd.read_csv('MSC_Dissertation_test_original3.csv')\n",
    "faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = faults.iloc[:, 1:21].values\n",
    "y = faults.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "VYP9cQTWbzuI",
    "outputId": "797e7a64-9bac-436a-8c9c-94437e5e7587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.000e+00  0.000e+00  1.130e+00 ... -1.243e-01  0.000e+00 -1.667e-01]\n",
      " [ 1.000e+00  1.000e+00  1.108e+00 ... -1.219e-01  0.000e+00 -1.634e-01]\n",
      " [ 2.000e+00  1.000e+00  1.345e+02 ... -1.243e-01  0.000e+00 -1.666e-01]\n",
      " ...\n",
      " [ 1.200e+01  4.000e+00  1.130e+00 ... -1.243e-01  0.000e+00 -1.667e-01]\n",
      " [ 1.200e+01  4.000e+00  1.130e+00 ... -1.243e-01  0.000e+00 -1.667e-01]\n",
      " [ 1.200e+01  4.000e+00  1.130e+00 ... -1.243e-01  0.000e+00 -1.667e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "38vKGE6Nb2RR",
    "outputId": "a815e42a-e0dd-4cb5-ab97-b17ead98fbc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.    1.    2.3   2.5   2.7   2.9   3.    4.25  4.5   4.75  4.9   5.\n",
      "  6.3   6.5   6.7   6.9   7.3   7.5   7.7   7.9   8.3   8.5   8.7   8.9\n",
      "  9.3   9.5   9.7   9.9  10.3  10.5  10.7  10.9  11.3  11.5  11.7  11.9\n",
      " 12.3  12.5  12.7  12.9   1.    2.3   2.5   2.7   2.9   3.    4.25  4.5\n",
      "  4.75  4.9   5.    6.3   6.5   6.7   6.9   7.3   7.5   7.7   7.9   8.3\n",
      "  8.5   8.7   8.9   9.3   9.5   9.7   9.9  10.3  10.5  10.7  10.9  11.3\n",
      " 11.5  11.7  11.9  12.3  12.5  12.7  12.9   1.    2.3   2.5   2.7   2.9\n",
      "  3.    4.25  4.5   4.75  4.9   5.    6.3   6.5   6.7   6.9   7.3   7.5\n",
      "  7.7   7.9   8.3   8.5   8.7   8.9   9.3   9.5   9.7   9.9  10.3  10.5\n",
      " 10.7  10.9  11.3  11.5  11.7  11.9  12.3  12.5  12.7  12.9   1.    2.3\n",
      "  2.5   2.7   2.9   3.    4.25  4.5   4.75  4.9   5.    6.3   6.5   6.7\n",
      "  6.9   7.3   7.5   7.7   7.9   8.3   8.5   8.7   8.9   9.3   9.5   9.7\n",
      "  9.9  10.3  10.5  10.7  10.9  11.3  11.5  11.7  11.9  12.3  12.5  12.7\n",
      " 12.9 ]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.compose import ColumnTransformer\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "#X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.    1.    2.3   2.5   2.7   2.9   3.    4.25  4.5   4.75  4.9   5.\n",
      "  6.3   6.5   6.7   6.9   7.3   7.5   7.7   7.9   8.3   8.5   8.7   8.9\n",
      "  9.3   9.5   9.7   9.9  10.3  10.5  10.7  10.9  11.3  11.5  11.7  11.9\n",
      " 12.3  12.5  12.7  12.9   1.    2.3   2.5   2.7   2.9   3.    4.25  4.5\n",
      "  4.75  4.9   5.    6.3   6.5   6.7   6.9   7.3   7.5   7.7   7.9   8.3\n",
      "  8.5   8.7   8.9   9.3   9.5   9.7   9.9  10.3  10.5  10.7  10.9  11.3\n",
      " 11.5  11.7  11.9  12.3  12.5  12.7  12.9   1.    2.3   2.5   2.7   2.9\n",
      "  3.    4.25  4.5   4.75  4.9   5.    6.3   6.5   6.7   6.9   7.3   7.5\n",
      "  7.7   7.9   8.3   8.5   8.7   8.9   9.3   9.5   9.7   9.9  10.3  10.5\n",
      " 10.7  10.9  11.3  11.5  11.7  11.9  12.3  12.5  12.7  12.9   1.    2.3\n",
      "  2.5   2.7   2.9   3.    4.25  4.5   4.75  4.9   5.    6.3   6.5   6.7\n",
      "  6.9   7.3   7.5   7.7   7.9   8.3   8.5   8.7   8.9   9.3   9.5   9.7\n",
      "  9.9  10.3  10.5  10.7  10.9  11.3  11.5  11.7  11.9  12.3  12.5  12.7\n",
      " 12.9 ]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHol938cW8zd"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-TDt0Y_XEfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE_FcHyfV3TQ"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViCrE00rV8Sk"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvdeScabXtlB"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3dtrScHxXQox"
   },
   "outputs": [],
   "source": [
    "ANN = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rP6urV6SX7kS"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bppGycBXYCQr"
   },
   "outputs": [],
   "source": [
    "ANN.add(tf.keras.layers.Dense(units=23, activation='relu'))\n",
    "ANN.add(tf.keras.layers.Dense(units=23, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BELWAc_8YJze"
   },
   "source": [
    "### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JneR0u0sYRTd"
   },
   "outputs": [],
   "source": [
    "ANN.add(tf.keras.layers.Dense(units=23, activation='relu'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyNEe6RXYcU4"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3x41RBYfvY"
   },
   "outputs": [],
   "source": [
    "ANN.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GWlJChhY_ZI"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG3RrwDXZEaS"
   },
   "outputs": [],
   "source": [
    "ANN.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QR_G5u7ZLSM"
   },
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nHZ-LKv_ZRb3",
    "outputId": "718cc4b0-b5aa-40f0-9b20-d3d31730a531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 [==============================] - 1s 3ms/step - loss: 75.3998 - accuracy: 0.0071\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 73.0327 - accuracy: 0.0071\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 70.7817 - accuracy: 0.0071\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 68.5419 - accuracy: 0.0071\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 66.1492 - accuracy: 0.0213\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 63.4977 - accuracy: 0.0213\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 60.5031 - accuracy: 0.0284\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 57.1611 - accuracy: 0.0284\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 53.2168 - accuracy: 0.0284\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 48.9357 - accuracy: 0.0284\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 44.1649 - accuracy: 0.0284\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 38.9771 - accuracy: 0.0284\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 33.5026 - accuracy: 0.0284\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 28.3868 - accuracy: 0.0284\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 23.4139 - accuracy: 0.0284\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 18.9499 - accuracy: 0.0284\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 15.5283 - accuracy: 0.0284\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 12.5198 - accuracy: 0.0284\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10.2498 - accuracy: 0.0284\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.7844 - accuracy: 0.0284\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4926 - accuracy: 0.0284\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.5059 - accuracy: 0.0284\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6517 - accuracy: 0.0284\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.9489 - accuracy: 0.0284\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.4180 - accuracy: 0.0284\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9448 - accuracy: 0.0284\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.5614 - accuracy: 0.0284\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.2543 - accuracy: 0.0284\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9399 - accuracy: 0.0284\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.6649 - accuracy: 0.0284\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.4453 - accuracy: 0.0284\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.2276 - accuracy: 0.0284\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0238 - accuracy: 0.0284\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.8514 - accuracy: 0.0284\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6996 - accuracy: 0.0284\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.5696 - accuracy: 0.0284\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4508 - accuracy: 0.0284\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.3492 - accuracy: 0.0284\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2586 - accuracy: 0.0284\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1697 - accuracy: 0.0284\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0978 - accuracy: 0.0284\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0293 - accuracy: 0.0284\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9730 - accuracy: 0.0284\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9108 - accuracy: 0.0284\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8674 - accuracy: 0.0284\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8165 - accuracy: 0.0284\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7787 - accuracy: 0.0284\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7403 - accuracy: 0.0284\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7055 - accuracy: 0.0284\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6754 - accuracy: 0.0284\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6464 - accuracy: 0.0284\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.0284\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.0284\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5698 - accuracy: 0.0284\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.0284\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.0284\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.0284\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.0284\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.0284\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.0284\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 347us/step - loss: 0.4445 - accuracy: 0.0284\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.0284\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 245us/step - loss: 0.4177 - accuracy: 0.0284\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 366us/step - loss: 0.4095 - accuracy: 0.0284\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 423us/step - loss: 0.3962 - accuracy: 0.0284\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3850 - accuracy: 0.0284\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.0284\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.0284\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.0284\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 298us/step - loss: 0.3488 - accuracy: 0.0284\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.0284\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.0284\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.0284\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3224 - accuracy: 0.0284\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.0284\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3071 - accuracy: 0.0284\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3011 - accuracy: 0.0284\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.0284\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2899 - accuracy: 0.0284\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2828 - accuracy: 0.0284\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.0284\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.0284\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.0284\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2611 - accuracy: 0.0284\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2584 - accuracy: 0.0284\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2552 - accuracy: 0.0284\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2483 - accuracy: 0.0284\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2434 - accuracy: 0.0284\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2409 - accuracy: 0.0284\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2356 - accuracy: 0.0284\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2319 - accuracy: 0.0284\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2269 - accuracy: 0.0284\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2234 - accuracy: 0.0284\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2210 - accuracy: 0.0284\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2162 - accuracy: 0.0284\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2147 - accuracy: 0.0284\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.0284\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2071 - accuracy: 0.0284\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2039 - accuracy: 0.0284\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2018 - accuracy: 0.0284\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.0284\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1971 - accuracy: 0.0284\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.0284\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 0.0284\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1869 - accuracy: 0.0284\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1844 - accuracy: 0.0284\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1807 - accuracy: 0.0284\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1818 - accuracy: 0.0284\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.0284\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.0284\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.1734 - accuracy: 0.0284\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1708 - accuracy: 0.0284\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1679 - accuracy: 0.0284\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1664 - accuracy: 0.0284\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.1637 - accuracy: 0.0284\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 602us/step - loss: 0.1621 - accuracy: 0.0284\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1600 - accuracy: 0.0284\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.0284\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.1556 - accuracy: 0.0284 \n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 471us/step - loss: 0.1538 - accuracy: 0.0284\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.1510 - accuracy: 0.0284\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.0284\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1460 - accuracy: 0.0284\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.0284\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.0284\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1417 - accuracy: 0.0284\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1391 - accuracy: 0.0284\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1386 - accuracy: 0.0284\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1364 - accuracy: 0.0284\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.0284\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1307 - accuracy: 0.0284\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.0284\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.1268 - accuracy: 0.0284 \n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 883us/step - loss: 0.1250 - accuracy: 0.0284\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1254 - accuracy: 0.0284\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.0284\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.0284\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.1190 - accuracy: 0.0284 \n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 482us/step - loss: 0.1173 - accuracy: 0.0284\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.0284\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.1147 - accuracy: 0.0284\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1127 - accuracy: 0.0284\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.0284\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.1104 - accuracy: 0.0284\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 441us/step - loss: 0.1082 - accuracy: 0.0284\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 643us/step - loss: 0.1091 - accuracy: 0.0284\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.0284\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.0284\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1043 - accuracy: 0.0284\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.0284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c27b7e9a00>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN.fit(X_train, y_train, batch_size = 32, epochs = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJj5k2MxZga3"
   },
   "source": [
    "##  Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84QFoqGYeXHL"
   },
   "source": [
    "### Predicting the result of a single observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2d8IoCCkeWGL",
    "outputId": "957f3970-e197-4c3b-a150-7f69dc567f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n",
      "[[2.61487]]\n"
     ]
    }
   ],
   "source": [
    "print(ANN.predict(sc.transform([[2,1,67.220,58.0600,64.360,0.00004835,0.0000518,0.00001254,0.4612,0.05777,0.2533,-0.9624,-0.4157,-0.8716,0,-0.331700,-0.07942,-0.1243,0,-0.1667]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7yx47jPZt11"
   },
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "nIyEeQdRZwgs",
    "outputId": "82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step\n",
      "[[ 4.45870972  4.75      ]\n",
      " [ 4.04813051  3.        ]\n",
      " [ 7.6732707   7.3       ]\n",
      " [ 8.45492172  8.5       ]\n",
      " [11.64297962 11.5       ]\n",
      " [10.35725117 10.5       ]\n",
      " [ 7.56625605  7.5       ]\n",
      " [ 7.54782295  7.9       ]\n",
      " [ 7.59320068  7.3       ]\n",
      " [ 8.45492172  8.7       ]\n",
      " [ 7.26322556  7.9       ]\n",
      " [ 7.82573938  7.5       ]\n",
      " [ 8.31591034  6.9       ]\n",
      " [10.56585026 10.7       ]\n",
      " [ 8.0841732   9.3       ]\n",
      " [10.54483604 10.7       ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ANN.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4302359342575073"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "mean_absolute_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35479727160356567"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "artificial_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
